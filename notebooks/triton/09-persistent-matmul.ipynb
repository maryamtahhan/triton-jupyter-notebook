{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Persistent Matmul\n",
    "This script demonstrates persistent kernel implementations of matrix multiplication using Triton.\n",
    "Various matmul methods are included, such as naive, persistent, and TMA (Tensor Memory Accelerator) based approaches.\n",
    "The kernels support both FP16 and FP8 data types but the FP8 implementation is only available on CUDA devices with compute capability >= 9.0.\n",
    "\n",
    "Triton and cuBLAS implementations are benchmarked under different configurations and evaluated using the proton profiler.\n",
    "Users can pass command-line arguments to specify matrix dimensions and iteration steps flexibly.\n",
    "\n",
    "```bash\n",
    "# FP8\n",
    "python 09-persistent-matmul.py --prec fp8 --K_range 128 1024 --K_step 128\n",
    "\n",
    "# FP16\n",
    "python 09-persistent-matmul.py --prec fp16 --K_range 128 1024 --K_step 128\n",
    "```\n",
    "Note that currently this tutorial will fail on devices with a small shared memory size, such as RTX-4090.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import triton.tools.experimental_descriptor\n",
    "import triton.profiler as proton\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from triton._C.libtriton import nvidia\n",
    "\n",
    "    cublas_workspace = torch.empty(32 * 1024 * 1024, device=\"cuda\", dtype=torch.uint8)\n",
    "    cublas = nvidia.cublas.CublasLt(cublas_workspace)\n",
    "else:\n",
    "    cublas = None\n",
    "\n",
    "\n",
    "def is_cuda():\n",
    "    return triton.runtime.driver.active.get_current_target().backend == \"cuda\"\n",
    "\n",
    "\n",
    "def supports_tma():\n",
    "    return is_cuda() and torch.cuda.get_device_capability()[0] >= 9\n",
    "\n",
    "\n",
    "def _matmul_launch_metadata(grid, kernel, args):\n",
    "    ret = {}\n",
    "    M, N, K = args[\"M\"], args[\"N\"], args[\"K\"]\n",
    "    ret[\"name\"] = f\"{kernel.name} [M={M}, N={N}, K={K}]\"\n",
    "    if \"tiles_per_update\" in args:\n",
    "        ret[\n",
    "            \"name\"\n",
    "        ] = f\"{kernel.name} [M={M}, N={N}, K={K}, tiles_per_update={args['tiles_per_update']:02}]\"\n",
    "    if \"c_ptr\" in args:\n",
    "        bytes_per_elem = args[\"c_ptr\"].element_size()\n",
    "    else:\n",
    "        bytes_per_elem = 1 if args[\"FP8_OUTPUT\"] else 2\n",
    "    ret[f\"flops{bytes_per_elem * 8}\"] = 2.0 * M * N * K\n",
    "    ret[\"bytes\"] = bytes_per_elem * (M * K + N * K + M * N)\n",
    "    return ret\n",
    "\n",
    "\n",
    "@triton.jit(launch_metadata=_matmul_launch_metadata)\n",
    "def matmul_kernel(\n",
    "    a_ptr,\n",
    "    b_ptr,\n",
    "    c_ptr,  #\n",
    "    M,\n",
    "    N,\n",
    "    K,  #\n",
    "    stride_am,\n",
    "    stride_ak,  #\n",
    "    stride_bk,\n",
    "    stride_bn,  #\n",
    "    stride_cm,\n",
    "    stride_cn,  #\n",
    "    BLOCK_SIZE_M: tl.constexpr,  #\n",
    "    BLOCK_SIZE_N: tl.constexpr,  #\n",
    "    BLOCK_SIZE_K: tl.constexpr,  #\n",
    "    GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    start_m = pid_m * BLOCK_SIZE_M\n",
    "    start_n = pid_n * BLOCK_SIZE_N\n",
    "\n",
    "    offs_am = start_m + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_bn = start_n + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offs_am = tl.where(offs_am < M, offs_am, 0)\n",
    "    offs_bn = tl.where(offs_bn < N, offs_bn, 0)\n",
    "\n",
    "    offs_am = tl.max_contiguous(tl.multiple_of(offs_am, BLOCK_SIZE_M), BLOCK_SIZE_M)\n",
    "    offs_bn = tl.max_contiguous(tl.multiple_of(offs_bn, BLOCK_SIZE_N), BLOCK_SIZE_N)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        accumulator = tl.dot(a, b, accumulator)\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    if c_ptr.dtype.element_ty == tl.float8e4nv:\n",
    "        c = accumulator.to(tl.float8e4nv)\n",
    "    else:\n",
    "        c = accumulator.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def matmul(a, b):\n",
    "    configs = {\n",
    "        torch.float8_e4m3fn: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 128,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 4,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "        torch.float16: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 64,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 3,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "    }\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.dtype == b.dtype, \"Incompatible dtypes\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    dtype = a.dtype\n",
    "\n",
    "    c = torch.empty((M, N), device=a.device, dtype=dtype)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),\n",
    "    )\n",
    "    matmul_kernel[grid](\n",
    "        a,\n",
    "        b,\n",
    "        c,  #\n",
    "        M,\n",
    "        N,\n",
    "        K,  #\n",
    "        a.stride(0),\n",
    "        a.stride(1),  #\n",
    "        b.stride(0),\n",
    "        b.stride(1),  #\n",
    "        c.stride(0),\n",
    "        c.stride(1),  #\n",
    "        BLOCK_SIZE_M=configs[dtype][\"BLOCK_SIZE_M\"],  #\n",
    "        BLOCK_SIZE_N=configs[dtype][\"BLOCK_SIZE_N\"],  #\n",
    "        BLOCK_SIZE_K=configs[dtype][\"BLOCK_SIZE_K\"],  #\n",
    "        GROUP_SIZE_M=configs[dtype][\"GROUP_SIZE_M\"],  #\n",
    "        num_stages=configs[dtype][\"num_stages\"],  #\n",
    "        num_warps=configs[dtype][\"num_warps\"],  #\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "@triton.jit(launch_metadata=_matmul_launch_metadata)\n",
    "def matmul_kernel_persistent(\n",
    "    a_ptr,\n",
    "    b_ptr,\n",
    "    c_ptr,  #\n",
    "    M,\n",
    "    N,\n",
    "    K,  #\n",
    "    stride_am,\n",
    "    stride_ak,  #\n",
    "    stride_bk,\n",
    "    stride_bn,  #\n",
    "    stride_cm,\n",
    "    stride_cn,  #\n",
    "    BLOCK_SIZE_M: tl.constexpr,  #\n",
    "    BLOCK_SIZE_N: tl.constexpr,  #\n",
    "    BLOCK_SIZE_K: tl.constexpr,  #\n",
    "    GROUP_SIZE_M: tl.constexpr,  #\n",
    "    NUM_SMS: tl.constexpr,  #\n",
    "):\n",
    "    start_pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_tiles = num_pid_m * num_pid_n\n",
    "\n",
    "    tiles_per_SM = num_tiles // NUM_SMS\n",
    "    if start_pid < num_tiles % NUM_SMS:\n",
    "        tiles_per_SM += 1\n",
    "\n",
    "    tile_id = start_pid - NUM_SMS\n",
    "    ki = -1\n",
    "\n",
    "    offs_k_for_mask = tl.arange(0, BLOCK_SIZE_K)\n",
    "\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "\n",
    "    pid_m = 0\n",
    "    pid_n = 0\n",
    "    offs_am = tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_bn = tl.arange(0, BLOCK_SIZE_N)\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "    for _ in range(0, k_tiles * tiles_per_SM):\n",
    "        ki = tl.where(ki == k_tiles - 1, 0, ki + 1)\n",
    "        if ki == 0:\n",
    "            tile_id += NUM_SMS\n",
    "            group_id = tile_id // num_pid_in_group\n",
    "            first_pid_m = group_id * GROUP_SIZE_M\n",
    "            group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "            pid_m = first_pid_m + (tile_id % group_size_m)\n",
    "            pid_n = (tile_id % num_pid_in_group) // group_size_m\n",
    "\n",
    "            start_m = pid_m * BLOCK_SIZE_M\n",
    "            start_n = pid_n * BLOCK_SIZE_N\n",
    "            offs_am = start_m + tl.arange(0, BLOCK_SIZE_M)\n",
    "            offs_bn = start_n + tl.arange(0, BLOCK_SIZE_N)\n",
    "            offs_am = tl.where(offs_am < M, offs_am, 0)\n",
    "            offs_bn = tl.where(offs_bn < N, offs_bn, 0)\n",
    "            offs_am = tl.max_contiguous(\n",
    "                tl.multiple_of(offs_am, BLOCK_SIZE_M), BLOCK_SIZE_M\n",
    "            )\n",
    "            offs_bn = tl.max_contiguous(\n",
    "                tl.multiple_of(offs_bn, BLOCK_SIZE_N), BLOCK_SIZE_N\n",
    "            )\n",
    "        offs_k = ki * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "        a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "        b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "        a = tl.load(\n",
    "            a_ptrs, mask=offs_k_for_mask[None, :] < K - ki * BLOCK_SIZE_K, other=0.0\n",
    "        )\n",
    "        b = tl.load(\n",
    "            b_ptrs, mask=offs_k_for_mask[:, None] < K - ki * BLOCK_SIZE_K, other=0.0\n",
    "        )\n",
    "        accumulator = tl.dot(a, b, accumulator)\n",
    "\n",
    "        if ki == k_tiles - 1:\n",
    "            offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "            offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "            c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "            c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "            if c_ptr.dtype.element_ty == tl.float8e4nv:\n",
    "                c = accumulator.to(tl.float8e4nv)\n",
    "            else:\n",
    "                c = accumulator.to(tl.float16)\n",
    "            tl.store(c_ptrs, c, mask=c_mask)\n",
    "            accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "\n",
    "def matmul_persistent(a, b):\n",
    "    configs = {\n",
    "        torch.float8_e4m3fn: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 128,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 4,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "        torch.float16: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 64,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 3,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "    }\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.dtype == b.dtype, \"Incompatible dtypes\"\n",
    "    NUM_SMS = torch.cuda.get_device_properties(\"cuda\").multi_processor_count\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    dtype = a.dtype\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=dtype)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (\n",
    "        min(\n",
    "            NUM_SMS,\n",
    "            triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),\n",
    "        ),\n",
    "    )\n",
    "    matmul_kernel_persistent[grid](\n",
    "        a,\n",
    "        b,\n",
    "        c,  #\n",
    "        M,\n",
    "        N,\n",
    "        K,  #\n",
    "        a.stride(0),\n",
    "        a.stride(1),  #\n",
    "        b.stride(0),\n",
    "        b.stride(1),  #\n",
    "        c.stride(0),\n",
    "        c.stride(1),  #\n",
    "        BLOCK_SIZE_M=configs[dtype][\"BLOCK_SIZE_M\"],  #\n",
    "        BLOCK_SIZE_N=configs[dtype][\"BLOCK_SIZE_N\"],  #\n",
    "        BLOCK_SIZE_K=configs[dtype][\"BLOCK_SIZE_K\"],  #\n",
    "        GROUP_SIZE_M=configs[dtype][\"GROUP_SIZE_M\"],  #\n",
    "        NUM_SMS=NUM_SMS,  #\n",
    "        num_stages=configs[dtype][\"num_stages\"],  #\n",
    "        num_warps=configs[dtype][\"num_warps\"],  #\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "@triton.jit(launch_metadata=_matmul_launch_metadata)\n",
    "def matmul_kernel_tma_persistent(\n",
    "    a_desc_ptr,\n",
    "    b_desc_ptr,\n",
    "    c_desc_ptr,  #\n",
    "    M,\n",
    "    N,\n",
    "    K,  #\n",
    "    BLOCK_SIZE_M: tl.constexpr,  #\n",
    "    BLOCK_SIZE_N: tl.constexpr,  #\n",
    "    BLOCK_SIZE_K: tl.constexpr,  #\n",
    "    GROUP_SIZE_M: tl.constexpr,  #\n",
    "    FP8_OUTPUT: tl.constexpr,  #\n",
    "    NUM_SMS: tl.constexpr,\n",
    "):  #\n",
    "    dtype = tl.float8e4nv if FP8_OUTPUT else tl.float16\n",
    "    start_pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_tiles = num_pid_m * num_pid_n\n",
    "\n",
    "    tiles_per_SM = num_tiles // NUM_SMS\n",
    "    if start_pid < num_tiles % NUM_SMS:\n",
    "        tiles_per_SM += 1\n",
    "\n",
    "    tile_id = start_pid - NUM_SMS\n",
    "    ki = -1\n",
    "\n",
    "    pid_m = 0\n",
    "    pid_n = 0\n",
    "    offs_am = 0\n",
    "    offs_bn = 0\n",
    "\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "    for _ in range(0, k_tiles * tiles_per_SM):\n",
    "        ki = tl.where(ki == k_tiles - 1, 0, ki + 1)\n",
    "        if ki == 0:\n",
    "            tile_id += NUM_SMS\n",
    "            group_id = tile_id // num_pid_in_group\n",
    "            first_pid_m = group_id * GROUP_SIZE_M\n",
    "            group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "            pid_m = first_pid_m + (tile_id % group_size_m)\n",
    "            pid_n = (tile_id % num_pid_in_group) // group_size_m\n",
    "\n",
    "            offs_am = pid_m * BLOCK_SIZE_M\n",
    "            offs_bn = pid_n * BLOCK_SIZE_N\n",
    "\n",
    "        offs_k = ki * BLOCK_SIZE_K\n",
    "\n",
    "        a = tl._experimental_descriptor_load(\n",
    "            a_desc_ptr, [offs_am, offs_k], [BLOCK_SIZE_M, BLOCK_SIZE_K], dtype\n",
    "        )\n",
    "        b = tl._experimental_descriptor_load(\n",
    "            b_desc_ptr, [offs_bn, offs_k], [BLOCK_SIZE_N, BLOCK_SIZE_K], dtype\n",
    "        )\n",
    "        accumulator = tl.dot(a, b.T, accumulator)\n",
    "\n",
    "        if ki == k_tiles - 1:\n",
    "            c = accumulator.to(dtype)\n",
    "\n",
    "            tl._experimental_descriptor_store(c_desc_ptr, c, [offs_am, offs_bn])\n",
    "            accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "\n",
    "def matmul_tma_persistent(a, b):\n",
    "    # Autotuner does not work with TMA. Use manual config.\n",
    "    configs = {\n",
    "        torch.float8_e4m3fn: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 128,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 4,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "        torch.float16: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 64,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 3,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[1], \"Incompatible dimensions\"  # b is transposed\n",
    "    assert a.dtype == b.dtype, \"Incompatible dtypes\"\n",
    "\n",
    "    M, K = a.shape\n",
    "    N, K = b.shape\n",
    "    dtype = a.dtype\n",
    "\n",
    "    c = torch.empty((M, N), device=a.device, dtype=dtype)\n",
    "    desc_a = triton.tools.experimental_descriptor.create_2d_tma_descriptor(\n",
    "        a.data_ptr(),\n",
    "        M,\n",
    "        K,\n",
    "        configs[dtype][\"BLOCK_SIZE_M\"],\n",
    "        configs[dtype][\"BLOCK_SIZE_K\"],\n",
    "        a.element_size(),\n",
    "    )\n",
    "    desc_b = triton.tools.experimental_descriptor.create_2d_tma_descriptor(\n",
    "        b.data_ptr(),\n",
    "        N,\n",
    "        K,\n",
    "        configs[dtype][\"BLOCK_SIZE_N\"],\n",
    "        configs[dtype][\"BLOCK_SIZE_K\"],\n",
    "        b.element_size(),\n",
    "    )\n",
    "    desc_c = triton.tools.experimental_descriptor.create_2d_tma_descriptor(\n",
    "        c.data_ptr(),\n",
    "        M,\n",
    "        N,\n",
    "        configs[dtype][\"BLOCK_SIZE_M\"],\n",
    "        configs[dtype][\"BLOCK_SIZE_N\"],\n",
    "        c.element_size(),\n",
    "    )\n",
    "    NUM_SMS = torch.cuda.get_device_properties(\"cuda\").multi_processor_count\n",
    "\n",
    "    grid = lambda META: (\n",
    "        min(\n",
    "            NUM_SMS,\n",
    "            triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),\n",
    "        ),\n",
    "    )\n",
    "    matmul_kernel_tma_persistent[grid](\n",
    "        desc_a,\n",
    "        desc_b,\n",
    "        desc_c,  #\n",
    "        M,\n",
    "        N,\n",
    "        K,  #\n",
    "        BLOCK_SIZE_M=configs[dtype][\"BLOCK_SIZE_M\"],  #\n",
    "        BLOCK_SIZE_N=configs[dtype][\"BLOCK_SIZE_N\"],  #\n",
    "        BLOCK_SIZE_K=configs[dtype][\"BLOCK_SIZE_K\"],  #\n",
    "        GROUP_SIZE_M=configs[dtype][\"GROUP_SIZE_M\"],  #\n",
    "        FP8_OUTPUT=dtype == torch.float8_e4m3fn,  #\n",
    "        NUM_SMS=NUM_SMS,  #\n",
    "        num_stages=configs[dtype][\"num_stages\"],  #\n",
    "        num_warps=configs[dtype][\"num_warps\"],  #\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "@triton.jit(launch_metadata=_matmul_launch_metadata)\n",
    "def matmul_kernel_descriptor_persistent(\n",
    "    tiles_per_update: tl.constexpr,  #\n",
    "    a_ptr,\n",
    "    b_ptr,\n",
    "    c_ptr,  #\n",
    "    M,\n",
    "    N,\n",
    "    K,  #\n",
    "    BLOCK_SIZE_M: tl.constexpr,  #\n",
    "    BLOCK_SIZE_N: tl.constexpr,  #\n",
    "    BLOCK_SIZE_K: tl.constexpr,  #\n",
    "    GROUP_SIZE_M: tl.constexpr,  #\n",
    "    NUM_SMS: tl.constexpr,\n",
    "):  #\n",
    "    # Matmul using TMA and device-side descriptor creation\n",
    "    dtype = c_ptr.dtype.element_ty\n",
    "    start_pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    k_tiles = tl.cdiv(K, BLOCK_SIZE_K)\n",
    "    num_tiles = num_pid_m * num_pid_n\n",
    "\n",
    "    a_desc = tl._experimental_make_tensor_descriptor(\n",
    "        a_ptr,\n",
    "        shape=[M, K],\n",
    "        strides=[K, 1],\n",
    "        block_shape=[BLOCK_SIZE_M, BLOCK_SIZE_K],\n",
    "    )\n",
    "    b_desc = tl._experimental_make_tensor_descriptor(\n",
    "        b_ptr,\n",
    "        shape=[N, K],\n",
    "        strides=[K, 1],\n",
    "        block_shape=[BLOCK_SIZE_N, BLOCK_SIZE_K],\n",
    "    )\n",
    "    c_desc = tl._experimental_make_tensor_descriptor(\n",
    "        c_ptr,\n",
    "        shape=[M, N],\n",
    "        strides=[N, 1],\n",
    "        block_shape=[BLOCK_SIZE_M, BLOCK_SIZE_N],\n",
    "    )\n",
    "\n",
    "    tiles_per_SM = num_tiles // NUM_SMS\n",
    "    if start_pid < num_tiles % NUM_SMS:\n",
    "        tiles_per_SM += 1\n",
    "\n",
    "    tile_id = start_pid - NUM_SMS\n",
    "    ki = -1\n",
    "    ni = -1\n",
    "\n",
    "    pid_m = 0\n",
    "    pid_n = 0\n",
    "    offs_am = 0\n",
    "    offs_bn = 0\n",
    "\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    # Create an opaque value to prevent the descriptor creation from being\n",
    "    # hoisted out of the loop\n",
    "    zero = tl.inline_asm_elementwise(\n",
    "        \"mov.b32 $0, 0;\", \"=r\", [], dtype=tl.int32, is_pure=True, pack=1\n",
    "    )\n",
    "\n",
    "    for _ in range(0, k_tiles * tiles_per_SM):\n",
    "        ki = tl.where(ki == k_tiles - 1, 0, ki + 1)\n",
    "        if ki == 0:\n",
    "            ni += 1\n",
    "\n",
    "            # Simulate a grouped gemm\n",
    "            if ni == tiles_per_update:\n",
    "                a_desc = tl._experimental_make_tensor_descriptor(\n",
    "                    a_ptr + zero,\n",
    "                    shape=[M, K],\n",
    "                    strides=[K, 1],\n",
    "                    block_shape=[BLOCK_SIZE_M, BLOCK_SIZE_K],\n",
    "                )\n",
    "                b_desc = tl._experimental_make_tensor_descriptor(\n",
    "                    b_ptr + zero,\n",
    "                    shape=[N, K],\n",
    "                    strides=[K, 1],\n",
    "                    block_shape=[BLOCK_SIZE_N, BLOCK_SIZE_K],\n",
    "                )\n",
    "                c_desc = tl._experimental_make_tensor_descriptor(\n",
    "                    c_ptr + zero,\n",
    "                    shape=[M, N],\n",
    "                    strides=[N, 1],\n",
    "                    block_shape=[BLOCK_SIZE_M, BLOCK_SIZE_N],\n",
    "                )\n",
    "                ni = 0\n",
    "\n",
    "            tile_id += NUM_SMS\n",
    "            group_id = tile_id // num_pid_in_group\n",
    "            first_pid_m = group_id * GROUP_SIZE_M\n",
    "            group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "            pid_m = first_pid_m + (tile_id % group_size_m)\n",
    "            pid_n = (tile_id % num_pid_in_group) // group_size_m\n",
    "\n",
    "            offs_am = pid_m * BLOCK_SIZE_M\n",
    "            offs_bn = pid_n * BLOCK_SIZE_N\n",
    "\n",
    "        offs_k = ki * BLOCK_SIZE_K\n",
    "\n",
    "        a = a_desc.load([offs_am, offs_k])\n",
    "        b = b_desc.load([offs_bn, offs_k])\n",
    "        accumulator = tl.dot(a, b.T, accumulator)\n",
    "\n",
    "        if ki == k_tiles - 1:\n",
    "            c = accumulator.to(dtype)\n",
    "\n",
    "            c_desc.store([offs_am, offs_bn], c)\n",
    "\n",
    "            accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "\n",
    "def matmul_descriptor_persistent(a, b, tiles_per_update):\n",
    "    # Autotuner does not work with TMA. Use manual config.\n",
    "    configs = {\n",
    "        torch.float8_e4m3fn: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 128,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 4,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "        torch.float16: {\n",
    "            \"BLOCK_SIZE_M\": 128,\n",
    "            \"BLOCK_SIZE_N\": 256,\n",
    "            \"BLOCK_SIZE_K\": 64,\n",
    "            \"GROUP_SIZE_M\": 8,\n",
    "            \"num_stages\": 3,\n",
    "            \"num_warps\": 8,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[1], \"Incompatible dimensions\"  # b is transposed\n",
    "    assert a.dtype == b.dtype, \"Incompatible dtypes\"\n",
    "\n",
    "    M, K = a.shape\n",
    "    N, K = b.shape\n",
    "    dtype = a.dtype\n",
    "\n",
    "    c = torch.empty((M, N), device=a.device, dtype=dtype)\n",
    "    NUM_SMS = torch.cuda.get_device_properties(\"cuda\").multi_processor_count\n",
    "\n",
    "    # TMA descriptors require a global memory allocation\n",
    "    def alloc_fn(size: int, alignment: int, stream: Optional[int]):\n",
    "        return torch.empty(size, device=\"cuda\", dtype=torch.int8)\n",
    "\n",
    "    triton.set_allocator(alloc_fn)\n",
    "\n",
    "    grid = lambda META: (\n",
    "        min(\n",
    "            NUM_SMS,\n",
    "            triton.cdiv(M, META[\"BLOCK_SIZE_M\"]) * triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),\n",
    "        ),\n",
    "    )\n",
    "    matmul_kernel_descriptor_persistent[grid](\n",
    "        tiles_per_update,  #\n",
    "        a,\n",
    "        b,\n",
    "        c,  #\n",
    "        M,\n",
    "        N,\n",
    "        K,  #\n",
    "        BLOCK_SIZE_M=configs[dtype][\"BLOCK_SIZE_M\"],  #\n",
    "        BLOCK_SIZE_N=configs[dtype][\"BLOCK_SIZE_N\"],  #\n",
    "        BLOCK_SIZE_K=configs[dtype][\"BLOCK_SIZE_K\"],  #\n",
    "        GROUP_SIZE_M=configs[dtype][\"GROUP_SIZE_M\"],  #\n",
    "        NUM_SMS=NUM_SMS,  #\n",
    "        num_stages=configs[dtype][\"num_stages\"],  #\n",
    "        num_warps=configs[dtype][\"num_warps\"],  #\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "def cublas_matmul(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[1], \"Incompatible dimensions\"  # b is transposed\n",
    "    M, K = a.shape\n",
    "    N, K = b.shape\n",
    "    dtype = a.dtype\n",
    "    c = torch.empty((M, N), device=a.device, dtype=dtype)\n",
    "    bytes_per_elem = a.element_size()\n",
    "    flops_str = f\"flops{bytes_per_elem * 8}\"\n",
    "    with proton.scope(\n",
    "        f\"cublas [M={M}, N={N}, K={K}]\",\n",
    "        {\"bytes\": bytes_per_elem * (M * K + N * K + M * N), flops_str: 2.0 * M * N * K},\n",
    "    ):\n",
    "        cublas.matmul(a, b, c)\n",
    "    return c\n",
    "\n",
    "\n",
    "def torch_matmul(a, b):\n",
    "    M, K = a.shape\n",
    "    N, K = b.shape\n",
    "    bytes_per_elem = a.element_size()\n",
    "    flops_str = f\"flops{bytes_per_elem * 8}\"\n",
    "    with proton.scope(\n",
    "        f\"torch [M={M}, N={N}, K={K}]\",\n",
    "        {\"bytes\": bytes_per_elem * (M * K + N * K + M * N), flops_str: 2.0 * M * N * K},\n",
    "    ):\n",
    "        c = torch.matmul(a, b.T)\n",
    "    return c\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def proton_context():\n",
    "    proton.activate(0)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        proton.deactivate(0)\n",
    "\n",
    "\n",
    "def bench_fn(reps, warmup_reps, fn, *args):\n",
    "    for _ in range(warmup_reps):\n",
    "        fn(*args)\n",
    "    with proton_context():\n",
    "        for _ in range(reps):\n",
    "            fn(*args)\n",
    "\n",
    "\n",
    "def bench(K, dtype, tiles_per_update, reps=1000, warmup_reps=10000):\n",
    "    M = 8192\n",
    "    N = 8192\n",
    "    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16).to(dtype)\n",
    "    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16).to(dtype)\n",
    "\n",
    "    b = b.T.contiguous()\n",
    "\n",
    "    if cublas is not None:\n",
    "        bench_fn(reps, warmup_reps, cublas_matmul, a, b)\n",
    "    if dtype == torch.float16:\n",
    "        bench_fn(reps, warmup_reps, torch_matmul, a, b)\n",
    "    bench_fn(reps, warmup_reps, matmul, a, b.T)\n",
    "    bench_fn(reps, warmup_reps, matmul_persistent, a, b.T)\n",
    "    if supports_tma():\n",
    "        bench_fn(reps, warmup_reps, matmul_tma_persistent, a, b)\n",
    "        bench_fn(\n",
    "            reps, warmup_reps, matmul_descriptor_persistent, a, b, tiles_per_update\n",
    "        )\n",
    "\n",
    "\n",
    "def validate(M, N, K, dtype, tiles_per_update):\n",
    "    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16).to(dtype)\n",
    "    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16).to(dtype)\n",
    "    b = b.T.contiguous()\n",
    "\n",
    "    torch_result = torch_matmul(a, b) if dtype == torch.float16 else None\n",
    "    cublas_result = cublas_matmul(a, b) if cublas is not None else None\n",
    "    naive_result = matmul(a, b.T)\n",
    "    persistent_result = matmul_persistent(a, b.T)\n",
    "    tma_persistent_result = matmul_tma_persistent(a, b) if supports_tma() else None\n",
    "    descriptor_persistent_result = (\n",
    "        matmul_descriptor_persistent(a, b, tiles_per_update) if supports_tma() else None\n",
    "    )\n",
    "\n",
    "    if torch_result is not None:\n",
    "        naive_vs_torch = (\n",
    "            \"✅\"\n",
    "            if torch.allclose(\n",
    "                naive_result.to(torch.float16), torch_result.to(torch.float16), atol=1.0\n",
    "            )\n",
    "            else \"❌\"\n",
    "        )\n",
    "    if cublas_result is not None:\n",
    "        naive_vs_cublas = (\n",
    "            \"✅\"\n",
    "            if torch.allclose(\n",
    "                naive_result.to(torch.float16),\n",
    "                cublas_result.to(torch.float16),\n",
    "                atol=1.0,\n",
    "            )\n",
    "            else \"❌\"\n",
    "        )\n",
    "    naive_vs_persistent = (\n",
    "        \"✅\"\n",
    "        if torch.allclose(\n",
    "            naive_result.to(torch.float16),\n",
    "            persistent_result.to(torch.float16),\n",
    "            atol=1.0,\n",
    "        )\n",
    "        else \"❌\"\n",
    "    )\n",
    "    if tma_persistent_result is not None:\n",
    "        naive_vs_tma_persistent = (\n",
    "            \"✅\"\n",
    "            if torch.allclose(\n",
    "                cublas_result.to(torch.float16),\n",
    "                tma_persistent_result.to(torch.float16),\n",
    "                atol=1.0,\n",
    "            )\n",
    "            else \"❌\"\n",
    "        )\n",
    "    if descriptor_persistent_result is not None:\n",
    "        naive_vs_descriptor_persistent = (\n",
    "            \"✅\"\n",
    "            if torch.allclose(\n",
    "                cublas_result.to(torch.float16),\n",
    "                descriptor_persistent_result.to(torch.float16),\n",
    "                atol=1.0,\n",
    "            )\n",
    "            else \"❌\"\n",
    "        )\n",
    "    print(f\"M={M}, N={N}, K={K} verification naive vs: \", end=\"\")\n",
    "    if torch_result is not None:\n",
    "        print(f\"torch: {naive_vs_torch} \", end=\"\")\n",
    "    if cublas_result is not None:\n",
    "        print(f\"cublas: {naive_vs_cublas} \", end=\"\")\n",
    "    print(f\"persistent: {naive_vs_persistent} \", end=\"\")\n",
    "    if tma_persistent_result is not None:\n",
    "        print(f\"TMA persistent: {naive_vs_tma_persistent} \", end=\"\")\n",
    "    if descriptor_persistent_result is not None:\n",
    "        print(f\"Device TMA persistent: {naive_vs_descriptor_persistent} \", end=\"\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def show_profile(precision, profile_name):\n",
    "    import triton.profiler.viewer as proton_viewer\n",
    "\n",
    "    metrics = [\"time/ms\"]\n",
    "    if precision == \"fp8\":\n",
    "        metrics = [\"tflop8/s\"] + metrics\n",
    "    elif precision == \"fp16\":\n",
    "        metrics = [\"tflop16/s\"] + metrics\n",
    "    file_name = f\"{profile_name}.hatchet\"\n",
    "    proton_viewer.parse(metrics, file_name, depth=100)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-K\", type=int, required=False, default=512)\n",
    "    parser.add_argument(\"--K_range\", type=int, nargs=2)\n",
    "    parser.add_argument(\"--K_step\", type=int, default=512)\n",
    "    parser.add_argument(\n",
    "        \"--tiles_per_update\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of output tiles calculated for each update of the tma descriptor in matmul_descriptor_persistent_kernel\",\n",
    "    )\n",
    "    parser.add_argument(\"--prec\", type=str, choices=[\"fp8\", \"fp16\"], default=\"fp16\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.prec == \"fp8\" and (not hasattr(torch, \"float8_e4m3fn\") or not is_cuda()):\n",
    "        print(\"This example requires CUDA with fp8 support.\")\n",
    "        exit(1)\n",
    "\n",
    "    dtype = torch.float8_e4m3fn if args.prec == \"fp8\" else torch.float16\n",
    "\n",
    "    if args.K and args.K_range is None:\n",
    "        args.K_range = [args.K, args.K]\n",
    "        args.K_step = 1  # doesn't matter as long as it's not 0\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    validate(32, 32, 32, dtype, args.tiles_per_update)\n",
    "    validate(8192, 8192, 512, dtype, args.tiles_per_update)\n",
    "\n",
    "    proton.start(\"matmul\", hook=\"triton\")\n",
    "    for K in range(args.K_range[0], args.K_range[1] + 1, args.K_step):\n",
    "        bench(K, dtype, args.tiles_per_update)\n",
    "    proton.finalize()\n",
    "    show_profile(args.prec, \"matmul\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
